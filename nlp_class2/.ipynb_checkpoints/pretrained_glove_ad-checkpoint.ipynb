{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://deeplearningcourses.com/c/data-science-natural-language-processing-in-python\n",
    "# https://www.udemy.com/data-science-natural-language-processing-in-python\n",
    "\n",
    "# Author: http://lazyprogrammer.me\n",
    "from __future__ import print_function, division\n",
    "from future.utils import iteritems\n",
    "from builtins import range\n",
    "# Note: you may need to update your version of future\n",
    "# sudo pip install -U future\n",
    "\n",
    "\n",
    "# WHERE TO GET THE VECTORS:\n",
    "# GloVe: https://nlp.stanford.edu/projects/glove/\n",
    "# Direct link: http://nlp.stanford.edu/data/glove.6B.zip\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist1(a, b):\n",
    "    return np.linalg.norm(a - b)\n",
    "def dist2(a, b):\n",
    "    return 1 - a.dot(b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "# pick a distance type\n",
    "dist, metric = dist2, 'cosine'\n",
    "# dist, metric = dist1, 'euclidean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## faster\n",
    "def find_analogies(w1, w2, w3):\n",
    "  for w in (w1, w2, w3):\n",
    "    if w not in word2vec:\n",
    "      print(\"%s not in dictionary\" % w)\n",
    "      return\n",
    "\n",
    "  king = word2vec[w1]\n",
    "  man = word2vec[w2]\n",
    "  woman = word2vec[w3]\n",
    "  v0 = king - man + woman\n",
    "\n",
    "  distances = pairwise_distances(v0.reshape(1, D), embedding, metric=metric).reshape(V)\n",
    "  idxs = distances.argsort()[:4]\n",
    "  for idx in idxs:\n",
    "    word = idx2word[idx]\n",
    "    if word not in (w1, w2, w3): \n",
    "      best_word = word\n",
    "      break\n",
    "\n",
    "  print(w1, \"-\", w2, \"=\", best_word, \"-\", w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbors(w, n=5):\n",
    "  if w not in word2vec:\n",
    "    print(\"%s not in dictionary:\" % w)\n",
    "    return\n",
    "\n",
    "  v = word2vec[w]\n",
    "  distances = pairwise_distances(v.reshape(1, D), embedding, metric=metric).reshape(V)\n",
    "  idxs = distances.argsort()[1:n+1]\n",
    "  print(\"neighbors of: %s\" % w)\n",
    "  for idx in idxs:\n",
    "    print(\"\\t%s\" % idx2word[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "the 0.418 0.24968 -0.41242 0.1217 0.34527 -0.044457 -0.49688 -0.17862 -0.00066023 -0.6566 0.27843 -0.14767 -0.55677 0.14658 -0.0095095 0.011658 0.10204 -0.12792 -0.8443 -0.12181 -0.016801 -0.33279 -0.1552 -0.23131 -0.19181 -1.8823 -0.76746 0.099051 -0.42125 -0.19526 4.0071 -0.18594 -0.52287 -0.31681 0.00059213 0.0074449 0.17778 -0.15897 0.012041 -0.054223 -0.29871 -0.15749 -0.34758 -0.045637 -0.44251 0.18785 0.0027849 -0.18411 -0.11514 -0.78581\n",
      "\n",
      "['the', '0.418', '0.24968', '-0.41242', '0.1217', '0.34527', '-0.044457', '-0.49688', '-0.17862', '-0.00066023', '-0.6566', '0.27843', '-0.14767', '-0.55677', '0.14658', '-0.0095095', '0.011658', '0.10204', '-0.12792', '-0.8443', '-0.12181', '-0.016801', '-0.33279', '-0.1552', '-0.23131', '-0.19181', '-1.8823', '-0.76746', '0.099051', '-0.42125', '-0.19526', '4.0071', '-0.18594', '-0.52287', '-0.31681', '0.00059213', '0.0074449', '0.17778', '-0.15897', '0.012041', '-0.054223', '-0.29871', '-0.15749', '-0.34758', '-0.045637', '-0.44251', '0.18785', '0.0027849', '-0.18411', '-0.11514', '-0.78581']\n",
      "the\n",
      "[ 4.1800e-01  2.4968e-01 -4.1242e-01  1.2170e-01  3.4527e-01 -4.4457e-02\n",
      " -4.9688e-01 -1.7862e-01 -6.6023e-04 -6.5660e-01  2.7843e-01 -1.4767e-01\n",
      " -5.5677e-01  1.4658e-01 -9.5095e-03  1.1658e-02  1.0204e-01 -1.2792e-01\n",
      " -8.4430e-01 -1.2181e-01 -1.6801e-02 -3.3279e-01 -1.5520e-01 -2.3131e-01\n",
      " -1.9181e-01 -1.8823e+00 -7.6746e-01  9.9051e-02 -4.2125e-01 -1.9526e-01\n",
      "  4.0071e+00 -1.8594e-01 -5.2287e-01 -3.1681e-01  5.9213e-04  7.4449e-03\n",
      "  1.7778e-01 -1.5897e-01  1.2041e-02 -5.4223e-02 -2.9871e-01 -1.5749e-01\n",
      " -3.4758e-01 -4.5637e-02 -4.4251e-01  1.8785e-01  2.7849e-03 -1.8411e-01\n",
      " -1.1514e-01 -7.8581e-01]\n"
     ]
    }
   ],
   "source": [
    "#### Understand the structure of Glove data\n",
    "# load in pre-trained word vectors\n",
    "print('Loading word vectors...')\n",
    "word2vec = {}\n",
    "embedding = []\n",
    "idx2word = []\n",
    "counter = 0\n",
    "with open('../large_files/glove.6B/glove.6B.50d.txt', encoding='utf-8') as f:\n",
    "  # is just a space-separated text file in the format:\n",
    "  # word vec[0] vec[1] vec[2] ...\n",
    "  for line in f:\n",
    "    if counter <= 0:\n",
    "        print(line)\n",
    "        counter += 1\n",
    "        values = line.split()\n",
    "        print(values)\n",
    "        word = values[0]\n",
    "        print(word)\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        print(vec)\n",
    "        word2vec[word] = vec\n",
    "        embedding.append(vec)\n",
    "        idx2word.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in pre-trained word vectors\n",
    "print('Loading word vectors...')\n",
    "word2vec = {}\n",
    "embedding = []\n",
    "idx2word = []\n",
    "with open('../large_files/glove.6B/glove.6B.50d.txt', encoding='utf-8') as f:\n",
    "  # is just a space-separated text file in the format:\n",
    "  # word vec[0] vec[1] vec[2] ...\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vec = np.asarray(values[1:], dtype='float32')\n",
    "    word2vec[word] = vec\n",
    "    embedding.append(vec)\n",
    "    idx2word.append(word)\n",
    "print('Found %s word vectors.' % len(word2vec))\n",
    "embedding = np.array(embedding)\n",
    "V, D = embedding.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
